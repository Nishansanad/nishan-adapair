{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7ac0da-84f6-4a4f-8f9a-03946ec441ac",
   "metadata": {},
   "source": [
    "# Packages and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35f56d0-035c-4fd9-a5d8-c85b0164f48f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3736\\1515553985.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load packages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInputExample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "from sentence_transformers import models, losses, datasets, SentencesDataset\n",
    "from sentence_transformers import SentenceTransformer, util, InputExample\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6faa0e-07e3-43f5-8de5-e7b433278dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify variables\n",
    "model_name = \"bert-base-uncased\"\n",
    "train_batch_size = 20\n",
    "max_seq_length = 250\n",
    "num_epochs = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = SentenceTransformer(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db61c76e-d47e-470f-aca0-11a02b8682c3",
   "metadata": {},
   "source": [
    "# Load and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3d3a0-70fa-4eee-b099-ce538f74f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from huggingface\n",
    "dataset = load_dataset(\"multi_nli\")\n",
    "\n",
    "# and make dataset as dataframe for easier usage\n",
    "df = pd.DataFrame()\n",
    "df[\"premise\"] = dataset[\"train\"][\"premise\"]\n",
    "df[\"hypothesis\"] = dataset[\"train\"][\"hypothesis\"]\n",
    "df[\"genre\"] = dataset[\"train\"][\"genre\"]\n",
    "df[\"label\"] = dataset[\"train\"][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba982d7-8af9-40c6-a790-944dcb4a5533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataloader\n",
    "train_examples = []\n",
    "\n",
    "# Each different hierarchy needs a different label\n",
    "for i in df.iterrows():\n",
    "    if i[1][\"genre\"] == \"telephone\":\n",
    "        v = 0\n",
    "    elif i[1][\"genre\"] == \"government\":\n",
    "        v = 3\n",
    "    elif i[1][\"genre\"] == \"travel\":\n",
    "        v = 6\n",
    "    elif i[1][\"genre\"] == \"fiction\":\n",
    "        v = 9\n",
    "    elif i[1][\"genre\"] == \"slate\":\n",
    "        v = 12\n",
    "    lab = int(i[1][\"label\"]) + v\n",
    "    \n",
    "    train_examples.append(InputExample(texts=[i[1][\"premise\"], i[1][\"hypothesis\"]], label=lab))\n",
    "\n",
    "train_dataset = SentencesDataset(train_examples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3352f-d0f5-4d8c-9c3a-014b0ef77717",
   "metadata": {},
   "source": [
    "# Train and save triplet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219cfe7-5186-47d3-9567-11966544c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify loss function\n",
    "train_loss = losses.BatchAllTripletLoss(model=model)\n",
    "\n",
    "# Train\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=num_epochs,\n",
    "          show_progress_bar=True,\n",
    "          optimizer_params={'lr': 1e-05}\n",
    "          )\n",
    "\n",
    "# Save model\n",
    "model.save(\"model_triplet_mnli\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "common-cu110.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m89"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
